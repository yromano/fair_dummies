{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>ERM with DNN under penalty of Equalized Odds</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement here a regular Empirical Risk Minimization (ERM) of a Deep Neural Network (DNN) penalized to enforce an Equalized Odds constraint. More formally, given a dataset of size $n$ consisting of context features $x$, target $y$ and a sensitive information $z$ to protect, we want to solve\n",
    "$$\n",
    "\\text{argmin}_{h\\in\\mathcal{H}}\\frac{1}{n}\\sum_{i=1}^n \\ell(y_i, h(x_i)) + \\lambda \\chi^2|_1\n",
    "$$\n",
    "where $\\ell$ is for instance the MSE and the penalty is\n",
    "$$\n",
    "\\chi^2|_1 = \\left\\lVert\\chi^2\\left(\\hat{\\pi}(h(x)|y, z|y), \\hat{\\pi}(h(x)|y)\\otimes\\hat{\\pi}(z|y)\\right)\\right\\rVert_1\n",
    "$$\n",
    "where $\\hat{\\pi}$ denotes the empirical density estimated through a Gaussian KDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "\n",
    "We use here the _communities and crimes_ dataset that can be found on the UCI Machine Learning Repository (http://archive.ics.uci.edu/ml/datasets/communities+and+crime). Non-predictive information, such as city name, state... have been removed and the file is at the arff format for ease of loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join('../..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.data_loading import read_dataset\n",
    "x_train, y_train, z_train, x_test, y_test, z_test = read_dataset(name='crimes', fold=1)\n",
    "n, d = x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Deep Neural Network\n",
    "\n",
    "We define a very simple DNN for regression here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NetRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(NetRegression, self).__init__()\n",
    "        size = 50\n",
    "        self.first = nn.Linear(input_size, size)\n",
    "        self.fc = nn.Linear(size, size)\n",
    "        self.last = nn.Linear(size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.selu(self.first(x))\n",
    "        out = F.selu(self.fc(out))\n",
    "        out = self.last(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fairness-inducing regularizer\n",
    "We implement now the regularizer. The empirical densities $\\hat{\\pi}$ are estimated using a Gaussian KDE. The L1 functional norm is taken over the values of $y$.\n",
    "$$\n",
    "\\chi^2|_1 = \\left\\lVert\\chi^2\\left(\\hat{\\pi}(x|z, y|z), \\hat{\\pi}(x|z)\\otimes\\hat{\\pi}(y|z)\\right)\\right\\rVert_1\n",
    "$$\n",
    "This used to enforce the conditional independence $X \\perp Y \\,|\\, Z$.\n",
    "Practically, we will want to enforce $\\text{prediction} \\perp \\text{sensitive} \\,|\\, \\text{target}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facl.independence.density_estimation.pytorch_kde import kde\n",
    "from facl.independence.hgr import chi_2_cond\n",
    "\n",
    "def chi_squared_l1_kde(X, Y, Z):\n",
    "    return torch.mean(chi_2_cond(X, Y, Z, kde))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The fairness-penalized ERM\n",
    "\n",
    "We now implement the full learning loop. The regression loss used is the quadratic loss with a L2 regularization and the fairness-inducing penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "def regularized_learning(x_train, y_train, z_train, model, fairness_penalty, lr=1e-5, num_epochs=10):\n",
    "    # wrap dataset in torch tensors\n",
    "    Y = torch.tensor(y_train.astype(np.float32))\n",
    "    X = torch.tensor(x_train.astype(np.float32))\n",
    "    Z = torch.tensor(z_train.astype(np.float32))\n",
    "    dataset = data_utils.TensorDataset(X, Y, Z)\n",
    "    dataset_loader = data_utils.DataLoader(dataset=dataset, batch_size=200, shuffle=True)\n",
    "\n",
    "    # mse regression objective\n",
    "    data_fitting_loss = nn.MSELoss()\n",
    "\n",
    "    # stochastic optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "\n",
    "    for j in range(num_epochs):\n",
    "        for i, (x, y, z) in enumerate(dataset_loader):\n",
    "            def closure():\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(x).flatten()\n",
    "                loss = data_fitting_loss(outputs, y)                \n",
    "                loss += fairness_penalty(outputs, z, y)\n",
    "                loss.backward()\n",
    "                return loss\n",
    "\n",
    "            optimizer.step(closure)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "For the evaluation on the test set, we compute two metrics: the MSE (accuracy) and HGR$|_\\infty$ (fairness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facl.independence.hgr import hgr_cond\n",
    "\n",
    "def evaluate(model, x, y, z):\n",
    "    Y = torch.tensor(y.astype(np.float32))\n",
    "    Z = torch.Tensor(z.astype(np.float32))\n",
    "    X = torch.tensor(x.astype(np.float32))\n",
    "\n",
    "    prediction = model(X).detach().flatten()\n",
    "    loss = nn.MSELoss()(prediction, Y)\n",
    "    hgr_infty = np.max(hgr_cond(prediction, Z, Y, kde))\n",
    "    return loss.item(), hgr_infty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running everything together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([194])\n",
      "torch.Size([194])\n",
      "torch.Size([194])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([194])\n",
      "torch.Size([194])\n",
      "torch.Size([194])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([194])\n",
      "torch.Size([194])\n",
      "torch.Size([194])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([194])\n",
      "torch.Size([194])\n",
      "torch.Size([194])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([194])\n",
      "torch.Size([194])\n",
      "torch.Size([194])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([194])\n",
      "torch.Size([194])\n",
      "torch.Size([194])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n",
      "torch.Size([200])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0851fb93eebd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m model = regularized_learning(x_train, y_train, z_train, model=model, fairness_penalty=penalty, lr=lr, \\\n\u001b[0;32m---> 11\u001b[0;31m                              num_epochs=num_epochs)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhgr_infty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-0ed4b6662ed2>\u001b[0m in \u001b[0;36mregularized_learning\u001b[0;34m(x_train, y_train, z_train, model, fairness_penalty, lr, num_epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-0ed4b6662ed2>\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfairness_penalty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-45c4334508ef>\u001b[0m in \u001b[0;36mchi_squared_l1_kde\u001b[0;34m(X, Y, Z)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mchi_squared_l1_kde\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchi_2_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Google Drive/fairness_crt/fairness_aware_learning/facl/independence/hgr.py\u001b[0m in \u001b[0;36mchi_2_cond\u001b[0;34m(X, Y, Z, density)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \"\"\"\n\u001b[1;32m    111\u001b[0m     \u001b[0mdamping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mh3d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_joint_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdamping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdamping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mmarginal_xz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mmarginal_yz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/fairness_crt/fairness_aware_learning/facl/independence/hgr.py\u001b[0m in \u001b[0;36m_joint_3\u001b[0;34m(X, Y, Z, density, damping)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mh3d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoint_density\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdamping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mh3d\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mh3d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mh3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Google Drive/fairness_crt/fairness_aware_learning/facl/independence/density_estimation/pytorch_kde.py\u001b[0m in \u001b[0;36mpdf\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     33\u001b[0m         pdf_values = (\n\u001b[1;32m     34\u001b[0m                          \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbandwidth\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                      ).mean(dim=-1) / sqrt(2 * pi) / self.bandwidth\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpdf_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fro\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;34mr\"\"\"See :func:`torch.norm`\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_infos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrobenius_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrobenius_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nuc\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = NetRegression(d, 1)\n",
    "\n",
    "num_epochs = 20\n",
    "lr = 1e-5\n",
    "\n",
    "# $\\chi^2|_1$\n",
    "penalty_coefficient = 1.0\n",
    "penalty = chi_squared_l1_kde\n",
    "\n",
    "model = regularized_learning(x_train, y_train, z_train, model=model, fairness_penalty=penalty, lr=lr, \\\n",
    "                             num_epochs=num_epochs)\n",
    "\n",
    "mse, hgr_infty = evaluate(model, x_test, y_test, z_test)\n",
    "print(\"MSE:{} HGR_infty:{}\".format(mse, hgr_infty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
